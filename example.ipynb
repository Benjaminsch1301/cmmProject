{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Explanation of datareader for Meteorological dataset including 3 differents locations (APEX, Paranal and La Silla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages \n",
    "import torch\n",
    "from pymongo import MongoClient\n",
    "from AGG.extended_typing import ContinuousTimeGraphSample\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we connect to mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"Meteo_test\" \n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[db_name] \n",
    "main_collection = db[db_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we see how it would be one sample in our main collection, which has all the samples from the three locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('65fb39460630f2ec7f2790cb'),\n",
       " 'idx': 0,\n",
       " 'time': '2023-01-01T00:00:58',\n",
       " 'node_features': 11.03,\n",
       " 'type_index': 0,\n",
       " 'spatial_index': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_collection.find_one({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a sorted index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)  \n",
    "\n",
    "from create_train_test_collection import get_sorted_idx_list\n",
    "ids = get_sorted_idx_list(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this example we will use the first 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[257895,\n",
       " 257896,\n",
       " 257897,\n",
       " 257898,\n",
       " 257899,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 257900,\n",
       " 257901,\n",
       " 257902,\n",
       " 257903,\n",
       " 257904,\n",
       " 218880,\n",
       " 218881,\n",
       " 218882,\n",
       " 218883,\n",
       " 218884,\n",
       " 218885,\n",
       " 218886,\n",
       " 218887,\n",
       " 218888,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 257905,\n",
       " 257906,\n",
       " 257907,\n",
       " 257908,\n",
       " 257909]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids[:100]\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will be the parameters I will use:\n",
    "* remove: 0.3\n",
    "* stride: 5\n",
    "* context_len: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total targets:  30\n",
      "Total train nodes:  70\n",
      "Creating indexes of nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 57625.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from create_train_test_collection import get_graph_sample_idx\n",
    "samples:dict = get_graph_sample_idx(context_len = config['context_len'], \n",
    "                                stride = config['stride'], \n",
    "                                idx_list = ids, \n",
    "                                selection_size = config['remove']\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next dictionary of samples will have the keys as an id of the graph sample,  and its value as a list of two elements, the first element is a list that contains the id's of the document in the mongodb main collection (nodes), and the second element is also an id in mongodb collecition of the target of that graph sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[257895, 257896, 257898, 257899, 0, 2, 3, 5, 6, 8], 1],\n",
       " 1: [[257895, 257896, 257898, 257899, 0, 2, 3, 5, 6, 8], 4],\n",
       " 2: [[257895, 257896, 257898, 257899, 0, 2, 3, 5, 6, 8], 7],\n",
       " 3: [[257895, 257896, 257898, 257899, 0, 2, 3, 5, 6, 8], 257897],\n",
       " 4: [[2, 3, 5, 6, 8, 9, 10, 11, 12, 14], 4],\n",
       " 5: [[2, 3, 5, 6, 8, 9, 10, 11, 12, 14], 7],\n",
       " 6: [[2, 3, 5, 6, 8, 9, 10, 11, 12, 14], 13],\n",
       " 7: [[9, 10, 11, 12, 14, 17, 18, 20, 21, 22], 13],\n",
       " 8: [[9, 10, 11, 12, 14, 17, 18, 20, 21, 22], 15],\n",
       " 9: [[9, 10, 11, 12, 14, 17, 18, 20, 21, 22], 16],\n",
       " 10: [[9, 10, 11, 12, 14, 17, 18, 20, 21, 22], 19],\n",
       " 11: [[17, 18, 20, 21, 22, 23, 24, 25, 26, 27], 19],\n",
       " 12: [[23, 24, 25, 26, 27, 28, 29, 30, 31, 33], 32],\n",
       " 13: [[28, 29, 30, 31, 33, 34, 35, 37, 257900, 257902], 32],\n",
       " 14: [[28, 29, 30, 31, 33, 34, 35, 37, 257900, 257902], 36],\n",
       " 15: [[28, 29, 30, 31, 33, 34, 35, 37, 257900, 257902], 257901],\n",
       " 16: [[34, 35, 37, 257900, 257902, 218880, 218881, 218882, 218884, 218885],\n",
       "  218883],\n",
       " 17: [[34, 35, 37, 257900, 257902, 218880, 218881, 218882, 218884, 218885],\n",
       "  36],\n",
       " 18: [[34, 35, 37, 257900, 257902, 218880, 218881, 218882, 218884, 218885],\n",
       "  257901],\n",
       " 19: [[34, 35, 37, 257900, 257902, 218880, 218881, 218882, 218884, 218885],\n",
       "  257903],\n",
       " 20: [[34, 35, 37, 257900, 257902, 218880, 218881, 218882, 218884, 218885],\n",
       "  257904],\n",
       " 21: [[218880, 218881, 218882, 218884, 218885, 218886, 38, 40, 41, 42],\n",
       "  218883],\n",
       " 22: [[218880, 218881, 218882, 218884, 218885, 218886, 38, 40, 41, 42],\n",
       "  218887],\n",
       " 23: [[218880, 218881, 218882, 218884, 218885, 218886, 38, 40, 41, 42],\n",
       "  218888],\n",
       " 24: [[218880, 218881, 218882, 218884, 218885, 218886, 38, 40, 41, 42], 39],\n",
       " 25: [[218886, 38, 40, 41, 42, 44, 45, 46, 47, 48], 218887],\n",
       " 26: [[218886, 38, 40, 41, 42, 44, 45, 46, 47, 48], 218888],\n",
       " 27: [[218886, 38, 40, 41, 42, 44, 45, 46, 47, 48], 39],\n",
       " 28: [[218886, 38, 40, 41, 42, 44, 45, 46, 47, 48], 43],\n",
       " 29: [[44, 45, 46, 47, 48, 49, 51, 52, 53, 54], 50],\n",
       " 30: [[49, 51, 52, 53, 54, 55, 56, 57, 58, 59], 50],\n",
       " 31: [[55, 56, 57, 58, 59, 61, 62, 64, 65, 67], 60],\n",
       " 32: [[55, 56, 57, 58, 59, 61, 62, 64, 65, 67], 63],\n",
       " 33: [[55, 56, 57, 58, 59, 61, 62, 64, 65, 67], 66],\n",
       " 34: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 63],\n",
       " 35: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 66],\n",
       " 36: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 70],\n",
       " 37: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 71],\n",
       " 38: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 72],\n",
       " 39: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 73],\n",
       " 40: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 74],\n",
       " 41: [[61, 62, 64, 65, 67, 68, 69, 75, 257905, 257907], 257906]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 7,\n",
       " 257897,\n",
       " 4,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 32,\n",
       " 32,\n",
       " 36,\n",
       " 257901,\n",
       " 218883,\n",
       " 36,\n",
       " 257901,\n",
       " 257903,\n",
       " 257904,\n",
       " 218883,\n",
       " 218887,\n",
       " 218888,\n",
       " 39,\n",
       " 218887,\n",
       " 218888,\n",
       " 39,\n",
       " 43,\n",
       " 50,\n",
       " 50,\n",
       " 60,\n",
       " 63,\n",
       " 66,\n",
       " 63,\n",
       " 66,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 257906]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[samples[s][1] for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to create a train-test split, for that we create a collection for train and train graph samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 samples expeted to be inserted in train collection, and 12 in test collection.\n",
      "Starting to build graph samples...(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:06<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting samples in train collection...\n",
      "30  Samples inserted in collection \"train\" of database \"Meteo_test\"\n",
      "Starting to build graph samples...(test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting samples in test collection...\n",
      "12  Samples inserted in collection \"train\" of database \"Meteo_test\"\n"
     ]
    }
   ],
   "source": [
    "from create_train_test_collection import create_train_test_db\n",
    "with open('utils/yaml/int_name_normal_coef.yaml','r') as f:\n",
    "    int_name_normal_coef = yaml.safe_load(f)\n",
    "len_train, len_test = create_train_test_db(samples = samples, \n",
    "                                           config = config, \n",
    "                                           int_name_normal_coef = int_name_normal_coef,\n",
    "                                           test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it would be a sample in train collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66173ab48df25b180e166778'),\n",
       " 'time': [-0.00022376543209876544,\n",
       "  -0.00022376543209876544,\n",
       "  -0.00022376543209876544,\n",
       "  -0.00022376543209876544,\n",
       "  -0.00022376543209876544,\n",
       "  -0.00022376543209876544,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'node_features': [-0.61361513304406,\n",
       "  0.12777952322139885,\n",
       "  -0.5516757888136073,\n",
       "  -0.6367982181805324,\n",
       "  -0.6615026139340858,\n",
       "  -1.028877768986193,\n",
       "  0.6086707889238913,\n",
       "  0.37964792241395373,\n",
       "  -0.27859289479827803,\n",
       "  -0.41379477941577364],\n",
       " 'type_index': [0, 2, 3, 5, 6, 8, 8, 14, 26, 34],\n",
       " 'spatial_index': [0, 0, 0, 0, 0, 0, 2, 2, 2, 2],\n",
       " 'key_padding_mask': [False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " 'kaboom': 'kaboom',\n",
       " 'target': {'time': [-0.00022376543209876544],\n",
       "  'features': [-0.5368557226697135],\n",
       "  'type_index': [4],\n",
       "  'spatial_index': [0],\n",
       "  'dummy': None},\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_collection = db['train']\n",
    "sample = train_collection.find_one({})\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last document id is the output of the function create_train_test_db() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66173ab48df25b180e166795'),\n",
       " 'time': [7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  7.71604938271605e-06,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'node_features': [-0.19145693532453092,\n",
       "  1.2882563653766084,\n",
       "  1.2486282703581366,\n",
       "  1.224780851849927,\n",
       "  -0.09010486727815423,\n",
       "  -0.22469878366739834,\n",
       "  -0.19967327609728663,\n",
       "  -0.8137351769795824,\n",
       "  0.6186699380881273,\n",
       "  0.12479250750206229],\n",
       " 'type_index': [23, 24, 26, 27, 29, 30, 31, 37, 8, 0],\n",
       " 'spatial_index': [0, 0, 0, 0, 0, 0, 0, 0, 2, 2],\n",
       " 'key_padding_mask': [False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " 'kaboom': 'kaboom',\n",
       " 'target': {'time': [7.71604938271605e-06],\n",
       "  'features': [-0.8592934922919462],\n",
       "  'type_index': [36],\n",
       "  'spatial_index': [0],\n",
       "  'dummy': None},\n",
       " 'id': 29}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_document = train_collection.find_one({}, sort=[('_id', -1)])\n",
    "last_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create the attention_mask for the sample in order to give it as input to the class ContinuousTimeGraphSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContinuousTimeGraphSample(node_features=tensor([-0.6136,  0.1278, -0.5517, -0.6368, -0.6615, -1.0289,  0.6087,  0.3796,\n",
       "        -0.2786, -0.4138]), key_padding_mask=tensor([False, False, False, False, False, False, False, False, False, False]), edge_index=None, time=tensor([-0.0002, -0.0002, -0.0002, -0.0002, -0.0002, -0.0002,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000]), attention_mask=tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False]]), target=TargetNode(features=tensor([-0.5369]), type_index=tensor([4]), time=tensor([-0.0002]), spatial_index=tensor([0]), category_index=None), type_index=tensor([ 0,  2,  3,  5,  6,  8,  8, 14, 26, 34]), spatial_index=tensor([0, 0, 0, 0, 0, 0, 2, 2, 2, 2]), category_index=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if \"attention_mask\" not in sample or len(sample[\"attention_mask\"]) == 0:\n",
    "    sample[\"time\"] = torch.tensor(sample[\"time\"], dtype=torch.float)\n",
    "    sample[\"attention_mask\"] = sample[\"time\"].unsqueeze(-1).T < sample[\n",
    "        \"time\"\n",
    "    ].unsqueeze(-1)\n",
    "ContinuousTimeGraphSample(**sample) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
